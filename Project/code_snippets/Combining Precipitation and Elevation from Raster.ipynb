{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dense-brazil",
   "metadata": {},
   "source": [
    "# Combining Precipitation and Elevation from Raster\n",
    "\n",
    "In this notebook, I will create datasets needed for my analysis. This will involve combining all monthly datasets together, combining all daily datasets together and creating an elevation data file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-inspector",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "We need `ftplib` for managing FTP connections and `rasterio` for working with rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from ftplib import FTP_TLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-freeze",
   "metadata": {},
   "source": [
    "## Load centers\n",
    "\n",
    "We load in the centers file so we can use the coordinates for extracting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broken-attitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>898356</td>\n",
       "      <td>ARBOR HEALTH MORTON GENERAL HOSPITAL</td>\n",
       "      <td>521 ADAMS ST</td>\n",
       "      <td>WA</td>\n",
       "      <td>98356</td>\n",
       "      <td>46.555675</td>\n",
       "      <td>-122.280354</td>\n",
       "      <td>HOSPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2912601</td>\n",
       "      <td>VASSAR BROTHERS MEDICAL CENTER</td>\n",
       "      <td>45 READE PL</td>\n",
       "      <td>NY</td>\n",
       "      <td>12601</td>\n",
       "      <td>41.693859</td>\n",
       "      <td>-73.935786</td>\n",
       "      <td>HOSPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3214215</td>\n",
       "      <td>ERIE COUNTY MEDICAL CENTER</td>\n",
       "      <td>462 GRIDER ST</td>\n",
       "      <td>NY</td>\n",
       "      <td>14215</td>\n",
       "      <td>42.925077</td>\n",
       "      <td>-78.831146</td>\n",
       "      <td>HOSPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5514607</td>\n",
       "      <td>STRONG MEMORIAL HOSPITAL</td>\n",
       "      <td>601 ELMWOOD AVE</td>\n",
       "      <td>NY</td>\n",
       "      <td>14607</td>\n",
       "      <td>43.122809</td>\n",
       "      <td>-77.624259</td>\n",
       "      <td>HOSPITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6411030</td>\n",
       "      <td>NORTH SHORE UNIVERSITY HOSPITAL</td>\n",
       "      <td>300 COMMUNITY DR</td>\n",
       "      <td>NY</td>\n",
       "      <td>11030</td>\n",
       "      <td>40.777636</td>\n",
       "      <td>-73.701611</td>\n",
       "      <td>HOSPITAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                  NAME           ADDRESS STATE  \\\n",
       "0   898356  ARBOR HEALTH MORTON GENERAL HOSPITAL      521 ADAMS ST    WA   \n",
       "1  2912601        VASSAR BROTHERS MEDICAL CENTER       45 READE PL    NY   \n",
       "2  3214215            ERIE COUNTY MEDICAL CENTER     462 GRIDER ST    NY   \n",
       "3  5514607              STRONG MEMORIAL HOSPITAL   601 ELMWOOD AVE    NY   \n",
       "4  6411030       NORTH SHORE UNIVERSITY HOSPITAL  300 COMMUNITY DR    NY   \n",
       "\n",
       "     ZIP   LATITUDE   LONGITUDE      TYPE  \n",
       "0  98356  46.555675 -122.280354  HOSPITAL  \n",
       "1  12601  41.693859  -73.935786  HOSPITAL  \n",
       "2  14215  42.925077  -78.831146  HOSPITAL  \n",
       "3  14607  43.122809  -77.624259  HOSPITAL  \n",
       "4  11030  40.777636  -73.701611  HOSPITAL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_data = pd.read_csv(\"../data/centers_data/combined_centers_data.csv\")\n",
    "centers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-copper",
   "metadata": {},
   "source": [
    "I'll extract the coordinates which will be needed for getting the corresponding data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ideal-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(x,y) for x, y in zip(centers_data[\"LONGITUDE\"], centers_data[\"LATITUDE\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-lancaster",
   "metadata": {},
   "source": [
    "## Load credentials\n",
    "\n",
    "Access to data is through an authorized ftp connections, so we need to load in our credentials. I have kept the credentials inside the file **eosdis_credentials.json** as a json format which I read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "miniature-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open credentials file\n",
    "credentials_file = open(\"../eosdis_credentials.json\")\n",
    "\n",
    "# Load credentials\n",
    "credentials = json.load(credentials_file)\n",
    "username = credentials[\"username\"]\n",
    "password = credentials[\"password\"]\n",
    "  \n",
    "# Close the file\n",
    "credentials_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-jungle",
   "metadata": {},
   "source": [
    "## Set up FTP\n",
    "\n",
    "We will now set up the FTP connection which we can use to get the data from the server. The set up instructions are taken from [GPM](https://gpm.nasa.gov/data/directory/imerg-final-run-pps-research-gis) download instructions for FTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prepared-assessment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200 Protection set to Private'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp_site = \"arthurhouftps.pps.eosdis.nasa.gov\"\n",
    "FTP_TLS.ssl_version = ssl.PROTOCOL_TLSv1_2\n",
    "ftps = FTP_TLS()\n",
    "ftps.connect(ftp_site, 21)\n",
    "ftps.login(username, password)\n",
    "ftps.prot_p()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-castle",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "We will now use the FTP connection to get the TIF files, extract data for the health centers and create our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-retention",
   "metadata": {},
   "source": [
    "### Monthly data download\n",
    "\n",
    "The following function enables us to download monthly precipitation data for a given date range for a given set of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "special-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_data(coords = [], ids = [], start_year = 2010, end_year = 2020):\n",
    "    \n",
    "    # If year is less than 2001, it won't work\n",
    "    if start_year < 2001:\n",
    "        print(\"ERROR: Start year must be more than 2000\")\n",
    "        return\n",
    "     \n",
    "    # If year is more than 2020, it won't work\n",
    "    if end_year > 2020:\n",
    "        print(\"ERROR: End year must be less than 2021\")\n",
    "        return\n",
    "    \n",
    "    # If end year is less than start year, it won't work\n",
    "    if end_year < start_year:\n",
    "        print(\"ERROR: End year must be after start year\")\n",
    "        return\n",
    "        \n",
    "    # Start creating a resultant dataframe\n",
    "    resultant_data = pd.DataFrame({\"ID\": ids, \"temp\": range(len(coords))})\n",
    "    \n",
    "    # For each year\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        \n",
    "        # For each month in the current year\n",
    "        for month in [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]:\n",
    "        \n",
    "            # Get the TIF file and save to local temporary file\n",
    "            f = open(\"temporary_tif.tif\", \"wb\")\n",
    "            ftps.retrbinary('RETR pub/gpmdata/' + str(year) + '/' + month + '/01/gis/3B-MO-GIS.MS.MRG.3IMERG.' + str(year) + month + '01-S000000-E235959.' + month + '.V06B.tif', f.write)\n",
    "            f.close()\n",
    "            \n",
    "            # Open that file\n",
    "            src = rasterio.open('temporary_tif.tif')\n",
    "            \n",
    "            # Get data from rastor\n",
    "            resultant_data[\"temp\"] = [x for x in src.sample(coords)]\n",
    "            resultant_data[month + \"_\" + str(year)] = resultant_data[\"temp\"].apply(lambda x: x[0])\n",
    "            \n",
    "            # Scale down by a factor of 1000 (documentation states the values are scaled up)\n",
    "            resultant_data[month + \"_\" + str(year)] = resultant_data[month + \"_\" + str(year)].div(1000)\n",
    "            \n",
    "            # Remove the temporary file\n",
    "            os.remove(\"temporary_tif.tif\")\n",
    "            \n",
    "        # Print when data is loaded for a given year\n",
    "        print(\"Completed extraction for {}\".format(year))\n",
    "        \n",
    "    # Return final dataframe\n",
    "    return resultant_data.drop([\"temp\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-civilization",
   "metadata": {},
   "source": [
    "I will download the monthly precipitation data for the years 2005 to 2020 and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hollow-mission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed extraction for 2005\n",
      "Completed extraction for 2006\n",
      "Completed extraction for 2007\n",
      "Completed extraction for 2008\n",
      "Completed extraction for 2009\n",
      "Completed extraction for 2010\n",
      "Completed extraction for 2011\n",
      "Completed extraction for 2012\n",
      "Completed extraction for 2013\n",
      "Completed extraction for 2014\n",
      "Completed extraction for 2015\n",
      "Completed extraction for 2016\n",
      "Completed extraction for 2017\n",
      "Completed extraction for 2018\n",
      "Completed extraction for 2019\n",
      "Completed extraction for 2020\n"
     ]
    }
   ],
   "source": [
    "prec_for_centers = get_monthly_data(coords, centers_data[\"ID\"], 2005, 2020)\n",
    "prec_for_centers.to_csv(\"../data/precipitation_data/prec_for_centers_monthly.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-torture",
   "metadata": {},
   "source": [
    "### Adding elevation data for monthly data\n",
    "\n",
    "Finally, I'll combine the elevation data I got from The **World TIF**, which is taken from [ASTER Global Digital Elevation Map](https://asterweb.jpl.nasa.gov/gdem.asp). The values are in metres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "proved-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elevation_data(coords, ids, elevation_file):\n",
    "      \n",
    "    # Create resultant dataframe\n",
    "    resultant_data = pd.DataFrame({\"ID\": ids})\n",
    "    \n",
    "    # Read the TIF file\n",
    "    src = rasterio.open(elevation_file)\n",
    "    \n",
    "    # Get elevation data\n",
    "    resultant_data[\"elevation\"] = [x for x in src.sample(coords)]\n",
    "    resultant_data[\"elevation\"] = resultant_data[\"elevation\"].apply(lambda x: x[0])\n",
    "        \n",
    "    # Return resultant data\n",
    "    return resultant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "female-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_for_centers = get_elevation_data(coords, centers_data[\"ID\"], \"../data/elevation_data/GDEM-10km-BW.tif\")\n",
    "elevation_for_centers.to_csv(\"../data/elevation_data/elevation_for_centers.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
